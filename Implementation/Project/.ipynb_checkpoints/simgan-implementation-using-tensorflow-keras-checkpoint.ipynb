{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:04.610732Z",
     "iopub.status.busy": "2021-12-05T14:46:04.610435Z",
     "iopub.status.idle": "2021-12-05T14:46:06.53241Z",
     "shell.execute_reply": "2021-12-05T14:46:06.531669Z",
     "shell.execute_reply.started": "2021-12-05T14:46:04.610684Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-e93f97989cbf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-e93f97989cbf>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install --upgrade pip\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import groupby\n",
    "from skimage.util import montage\n",
    "\n",
    "from keras.layers import Dense, Reshape, Input, BatchNormalization, Concatenate, Activation, Add\n",
    "from keras.layers.convolutional import UpSampling2D, MaxPooling2D, Deconv2D, Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD, Nadam, Adamax\n",
    "from keras import initializers\n",
    "from keras import applications\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.533872Z",
     "iopub.status.busy": "2021-12-05T14:46:06.533507Z",
     "iopub.status.idle": "2021-12-05T14:46:06.538718Z",
     "shell.execute_reply": "2021-12-05T14:46:06.537752Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.533687Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.540353Z",
     "iopub.status.busy": "2021-12-05T14:46:06.540098Z",
     "iopub.status.idle": "2021-12-05T14:46:06.548189Z",
     "shell.execute_reply": "2021-12-05T14:46:06.547378Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.540265Z"
    }
   },
   "outputs": [],
   "source": [
    "img_width = 55\n",
    "img_height = 35\n",
    "channels = 1\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.550475Z",
     "iopub.status.busy": "2021-12-05T14:46:06.550158Z",
     "iopub.status.idle": "2021-12-05T14:46:06.558545Z",
     "shell.execute_reply": "2021-12-05T14:46:06.557879Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.550424Z"
    }
   },
   "outputs": [],
   "source": [
    "def self_regularisation_loss(y_true, y_pred):\n",
    "    return tf.multiply(0.0002, tf.reduce_sum(tf.abs(y_pred - y_true)))\n",
    "\n",
    "# reduce_sum: Computes the sum of elements across dimensions of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.560074Z",
     "iopub.status.busy": "2021-12-05T14:46:06.559754Z",
     "iopub.status.idle": "2021-12-05T14:46:06.56818Z",
     "shell.execute_reply": "2021-12-05T14:46:06.567413Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.56002Z"
    }
   },
   "outputs": [],
   "source": [
    "def local_adversarial_loss(y_true, y_pred):\n",
    "    truth = tf.reshape(y_true, (-1, 2))\n",
    "    predicted = tf.reshape(y_pred, (-1, 2))\n",
    "    \n",
    "    computed_loss = tf.nn.softmax_cross_entropy_with_logits(labels=truth, logits=predicted)\n",
    "    output = tf.reduce_mean(computed_loss)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.569903Z",
     "iopub.status.busy": "2021-12-05T14:46:06.569589Z",
     "iopub.status.idle": "2021-12-05T14:46:06.579442Z",
     "shell.execute_reply": "2021-12-05T14:46:06.57855Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.569841Z"
    }
   },
   "outputs": [],
   "source": [
    "def refiner_model(width = 55, height = 35, channels = 1):\n",
    "    \"\"\"\n",
    "    The refiner network, Rθ, is a residual network (ResNet). It modifies the synthetic image on a pixel level, rather\n",
    "    than holistically modifying the image content, preserving the global structure and annotations.\n",
    "    \n",
    "    :param input_image_tensor: Input tensor that corresponds to a synthetic image.\n",
    "    :return: Output tensor that corresponds to a refined synthetic image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def resnet_block(input_features, nb_features=64, kernel_size=3):\n",
    "        \"\"\"\n",
    "        A ResNet block with two `kernel_size` x `kernel_size` convolutional layers,\n",
    "        each with `nb_features` feature maps.\n",
    "        \n",
    "        See Figure 6 in https://arxiv.org/pdf/1612.07828v1.pdf.\n",
    "        \n",
    "        :param input_features: Input tensor to ResNet block.\n",
    "        :return: Output tensor from ResNet block.\n",
    "        \"\"\"\n",
    "        y = Conv2D(nb_features, kernel_size=kernel_size, padding='same')(input_features)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Conv2D(nb_features, kernel_size=kernel_size, padding='same')(y)\n",
    "        \n",
    "        y = Add()([y, input_features])\n",
    "        y = Activation('relu')(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "    input_layer = Input(shape=(height, width, channels))\n",
    "    # an input image of size w × h is convolved with 3 × 3 filters that output 64 feature maps\n",
    "    x = Conv2D(64, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
    "\n",
    "    for _ in range(4):\n",
    "        x = resnet_block(x)\n",
    "\n",
    "    output_layer = Conv2D(channels, kernel_size=1, padding='same', activation='tanh')(x)\n",
    "\n",
    "    return Model(input_layer, output_layer, name='refiner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.580902Z",
     "iopub.status.busy": "2021-12-05T14:46:06.580591Z",
     "iopub.status.idle": "2021-12-05T14:46:06.595653Z",
     "shell.execute_reply": "2021-12-05T14:46:06.594707Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.580839Z"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_model(width = 55, height = 35, channels = 1):\n",
    "    input_layer = Input(shape=(height, width, channels))\n",
    "\n",
    "    x = Conv2D(96, kernel_size=3, strides=2, padding='same', activation='relu')(input_layer)\n",
    "    x = Conv2D(64, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=1, padding='same')(x)\n",
    "    x = Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(32, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(2, kernel_size=1, strides=1, padding='same', activation='relu')(x)\n",
    "    output_layer = Reshape(target_shape=(-1, 2))(x)\n",
    "\n",
    "    return Model(input_layer, output_layer, name='discriminator')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the SimGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.597387Z",
     "iopub.status.busy": "2021-12-05T14:46:06.597048Z",
     "iopub.status.idle": "2021-12-05T14:46:06.885191Z",
     "shell.execute_reply": "2021-12-05T14:46:06.884215Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.597329Z"
    }
   },
   "outputs": [],
   "source": [
    "refiner = refiner_model(img_width, img_height, channels)\n",
    "refiner.compile(loss=self_regularisation_loss, optimizer=SGD(lr=0.001))\n",
    "\n",
    "refiner.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:06.886573Z",
     "iopub.status.busy": "2021-12-05T14:46:06.886334Z",
     "iopub.status.idle": "2021-12-05T14:46:07.042241Z",
     "shell.execute_reply": "2021-12-05T14:46:07.041425Z",
     "shell.execute_reply.started": "2021-12-05T14:46:06.886531Z"
    }
   },
   "outputs": [],
   "source": [
    "disc = discriminator_model(img_width, img_height, channels)\n",
    "disc.compile(loss=local_adversarial_loss, optimizer=SGD(lr=0.001))\n",
    "\n",
    "disc.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:07.043761Z",
     "iopub.status.busy": "2021-12-05T14:46:07.043552Z",
     "iopub.status.idle": "2021-12-05T14:46:07.11861Z",
     "shell.execute_reply": "2021-12-05T14:46:07.117575Z",
     "shell.execute_reply.started": "2021-12-05T14:46:07.043722Z"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_img = Input(shape=(img_height, img_width, channels))\n",
    "refined_output = refiner(synthetic_img)\n",
    "discriminator_output = disc(refined_output)\n",
    "\n",
    "combined_model = Model(inputs=synthetic_img, outputs=[refined_output, discriminator_output], name='combined')\n",
    "combined_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:07.120104Z",
     "iopub.status.busy": "2021-12-05T14:46:07.119886Z",
     "iopub.status.idle": "2021-12-05T14:46:07.185839Z",
     "shell.execute_reply": "2021-12-05T14:46:07.184902Z",
     "shell.execute_reply.started": "2021-12-05T14:46:07.120063Z"
    }
   },
   "outputs": [],
   "source": [
    "disc.trainabler = False\n",
    "combined_model.compile(loss=[self_regularisation_loss, local_adversarial_loss], optimizer=SGD(lr=0.001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:07.187495Z",
     "iopub.status.busy": "2021-12-05T14:46:07.18721Z",
     "iopub.status.idle": "2021-12-05T14:46:07.191716Z",
     "shell.execute_reply": "2021-12-05T14:46:07.190647Z",
     "shell.execute_reply.started": "2021-12-05T14:46:07.187443Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.path.dirname(os.path.abspath('.'))\n",
    "data_dir = os.path.join('..', 'input')\n",
    "cache_dir = '.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:46:07.192972Z",
     "iopub.status.busy": "2021-12-05T14:46:07.192711Z",
     "iopub.status.idle": "2021-12-05T14:47:09.919814Z",
     "shell.execute_reply": "2021-12-05T14:47:09.918874Z",
     "shell.execute_reply.started": "2021-12-05T14:46:07.192911Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data file and extract dimentions\n",
    "with h5py.File(os.path.join(data_dir, 'gaze.h5'), 'r') as t_file:\n",
    "    syn_img_stack = np.stack([np.expand_dims(a, -1) for a in t_file['image'].values()], 0)\n",
    "    \n",
    "with h5py.File(os.path.join(data_dir, 'real_gaze.h5'), 'r') as t_file:\n",
    "    real_img_stack = np.stack([np.expand_dims(a, -1) for a in t_file['image'].values()], 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:09.921209Z",
     "iopub.status.busy": "2021-12-05T14:47:09.920997Z",
     "iopub.status.idle": "2021-12-05T14:47:09.927783Z",
     "shell.execute_reply": "2021-12-05T14:47:09.926852Z",
     "shell.execute_reply.started": "2021-12-05T14:47:09.921169Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module to plot a batch of images along w/ their corresponding label(s)/annotations and save the plot to disc/show them.\n",
    "\n",
    "Use cases:\n",
    "Plot images along w/ their corresponding ground-truth label & model predicted label,\n",
    "Plot images generated by a GAN along w/ any annotations used to generate these images,\n",
    "Plot synthetic, generated, refined, and real images and see how they compare as training progresses in a GAN,\n",
    "etc...\n",
    "\"\"\"\n",
    "plotted_imgs = 16\n",
    "\n",
    "def plot_batch(image_batch, figure_path, label_batch=None):\n",
    "    \n",
    "    all_groups = {label: montage(np.stack([img[:,:,0] for img, lab in img_lab_list],0)) \n",
    "                  for label, img_lab_list in groupby(zip(image_batch, label_batch), lambda x: x[1])}\n",
    "    fig, c_axs = plt.subplots(1,len(all_groups), figsize=(len(all_groups)*4, 8), dpi = 600)\n",
    "    for c_ax, (c_label, c_mtg) in zip(c_axs, all_groups.items()):\n",
    "        c_ax.imshow(c_mtg, cmap='bone')\n",
    "        c_ax.set_title(c_label)\n",
    "        c_ax.axis('off')\n",
    "    # fig.savefig(os.path.join(figure_path))\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:09.929911Z",
     "iopub.status.busy": "2021-12-05T14:47:09.929539Z",
     "iopub.status.idle": "2021-12-05T14:47:09.943508Z",
     "shell.execute_reply": "2021-12-05T14:47:09.942366Z",
     "shell.execute_reply.started": "2021-12-05T14:47:09.929807Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module implementing the image history buffer described in `2.3. Updating Discriminator using a History of\n",
    "Refined Images` of https://arxiv.org/pdf/1612.07828v1.pdf.\n",
    "\"\"\"\n",
    "\n",
    "class ImageHistoryBuffer():\n",
    "    def __init__(self, shape, max_size, batch_size):\n",
    "        \"\"\"\n",
    "        :param shape: Shape of the data to be stored in the image history buffer\n",
    "                      (i.e. (0, img_height, img_width, img_channels)).\n",
    "        :param max_size: Maximum number of images that can be stored in the image history buffer.\n",
    "        :param batch_size: Batch size used to train GAN.\n",
    "        \"\"\"\n",
    "        self.image_history_buffer = np.zeros(shape=shape)\n",
    "        self.max_size = max_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def add_to_history_img_buffer(self, images, nb_to_add=0):\n",
    "        if not nb_to_add:\n",
    "            nb_to_add = self.batch_size // 2\n",
    "        \n",
    "        if len(self.image_history_buffer) < self.max_size:\n",
    "            np.append(self.image_history_buffer, images[:nb_to_add], axis=0)\n",
    "        elif len(self.image_history_buffer) == self.max_size:\n",
    "            self.image_history_buffer[:nb_to_add] = images[:nb_to_add]\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        np.random.shuffle(self.image_history_buffer)\n",
    "    \n",
    "    def get_from_image_history_buffer(self, nb_to_get=None):\n",
    "        \"\"\"\n",
    "        Get a random sample of images from the history buffer.\n",
    "\n",
    "        :param nb_to_get: Number of images to get from the image history buffer (batch_size / 2 by default).\n",
    "        :return: A random sample of `nb_to_get` images from the image history buffer, or an empty np array if the image\n",
    "                 history buffer is empty.\n",
    "        \"\"\"\n",
    "        if not nb_to_get:\n",
    "            nb_to_get = self.batch_size // 2\n",
    "\n",
    "        try:\n",
    "            return self.image_history_buffer[:nb_to_get]\n",
    "        except IndexError:\n",
    "            return np.zeros(shape=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:09.946721Z",
     "iopub.status.busy": "2021-12-05T14:47:09.946494Z",
     "iopub.status.idle": "2021-12-05T14:47:09.956912Z",
     "shell.execute_reply": "2021-12-05T14:47:09.956265Z",
     "shell.execute_reply.started": "2021-12-05T14:47:09.946679Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = image.ImageDataGenerator(preprocessing_function=applications.xception.preprocess_input, data_format='channels_last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:09.958441Z",
     "iopub.status.busy": "2021-12-05T14:47:09.957972Z",
     "iopub.status.idle": "2021-12-05T14:47:10.435638Z",
     "shell.execute_reply": "2021-12-05T14:47:10.434774Z",
     "shell.execute_reply.started": "2021-12-05T14:47:09.958237Z"
    }
   },
   "outputs": [],
   "source": [
    "syn_gen = datagen.flow(x=syn_img_stack, batch_size=batch_size)\n",
    "real_gen = datagen.flow(x=real_img_stack, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:10.43699Z",
     "iopub.status.busy": "2021-12-05T14:47:10.436792Z",
     "iopub.status.idle": "2021-12-05T14:47:10.44265Z",
     "shell.execute_reply": "2021-12-05T14:47:10.441616Z",
     "shell.execute_reply.started": "2021-12-05T14:47:10.43696Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_batch(generator):\n",
    "    \"\"\"keras generators may generate an incomplete batch for the last batch\"\"\"\n",
    "    img_batch = generator.next()\n",
    "    if len(img_batch) != batch_size:\n",
    "        img_batch = generator.next()\n",
    "    \n",
    "    assert len(img_batch) == batch_size\n",
    "    \n",
    "    return img_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:10.443934Z",
     "iopub.status.busy": "2021-12-05T14:47:10.443722Z",
     "iopub.status.idle": "2021-12-05T14:47:10.45502Z",
     "shell.execute_reply": "2021-12-05T14:47:10.454393Z",
     "shell.execute_reply.started": "2021-12-05T14:47:10.443894Z"
    }
   },
   "outputs": [],
   "source": [
    "disc_output_shape = disc.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:10.457566Z",
     "iopub.status.busy": "2021-12-05T14:47:10.457189Z",
     "iopub.status.idle": "2021-12-05T14:47:10.523895Z",
     "shell.execute_reply": "2021-12-05T14:47:10.522966Z",
     "shell.execute_reply.started": "2021-12-05T14:47:10.457502Z"
    }
   },
   "outputs": [],
   "source": [
    "y_real = np.array([[[1.0, 0.0]] * disc_output_shape[1]] * batch_size)\n",
    "y_refined = np.array([[[0.0, 1.0]] * disc_output_shape[1]] * batch_size)\n",
    "\n",
    "assert y_real.shape == (batch_size, disc_output_shape[1], 2)\n",
    "assert y_refined.shape == (batch_size, disc_output_shape[1], 2)\n",
    "\n",
    "batch_out = get_image_batch(syn_gen)\n",
    "assert batch_out.shape == (batch_size, img_height, img_width, channels), \"Image dimension do not match, {} != {}\" \\\n",
    "    .format(batch_out.shape, (batch_size, img_height, img_width, img_channels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining\n",
    "\n",
    "Here we pretraining the models before we start the full-blown training procedure\n",
    "\n",
    "### Pretraining the Generator (Refiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:10.525692Z",
     "iopub.status.busy": "2021-12-05T14:47:10.525194Z",
     "iopub.status.idle": "2021-12-05T14:47:10.533695Z",
     "shell.execute_reply": "2021-12-05T14:47:10.532759Z",
     "shell.execute_reply.started": "2021-12-05T14:47:10.5255Z"
    }
   },
   "outputs": [],
   "source": [
    "def pretrain_gen(steps, log_interval, save_path, profiling=True):\n",
    "    losses = []\n",
    "    gen_loss = 0.\n",
    "    if profiling:\n",
    "        start = time.perf_counter()\n",
    "    for i in range(steps):\n",
    "        syn_imgs_batch = get_image_batch(syn_gen)\n",
    "        loss = refiner.train_on_batch(syn_imgs_batch, syn_imgs_batch)\n",
    "        gen_loss += loss\n",
    "\n",
    "        if (i+1) % log_interval == 0:\n",
    "            print('pre-training generator step {}/{}: loss = {:.5f}'.format(i+1, steps, gen_loss / log_interval))\n",
    "            losses.append(gen_loss / log_interval)\n",
    "            gen_loss = 0.\n",
    "        \n",
    "        if (i+1) % (5*log_interval) == 0:\n",
    "            figure_name = 'refined_img_pretrain_step_{}.png'.format(i)\n",
    "            syn_imgs = get_image_batch(syn_gen)[:plotted_imgs]\n",
    "            gen_imgs = refiner.predict_on_batch(syn_imgs)\n",
    "\n",
    "            plot_batch(np.concatenate((syn_imgs, gen_imgs)), os.path.join(cache_dir, figure_name), \n",
    "                       label_batch=['Synthetic'] * plotted_imgs + ['Refined'] * plotted_imgs)\n",
    "\n",
    "    if profiling:\n",
    "        duration = time.perf_counter() - start\n",
    "        print('pre-training the refiner model for {} steps lasted = {:.2f} minutes = {:.2f} hours'.format(steps, duration/60., duration/3600.))\n",
    "    \n",
    "#     refiner.save(save_path)\n",
    "    \n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2021-12-05T14:47:10.535047Z",
     "iopub.status.busy": "2021-12-05T14:47:10.534753Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# we first train the Rθ network with just self-regularization loss for 1,000 steps\n",
    "gen_pre_steps = 1000\n",
    "gen_log_interval = 20\n",
    "\n",
    "pre_gen_path = os.path.join(cache_dir, 'refiner_model_pre_trained_{}.h5'.format(gen_pre_steps))\n",
    "if os.path.isfile(pre_gen_path):\n",
    "    refiner.load_weights(pre_gen_path)\n",
    "    print('loading pretrained model weights')\n",
    "else:\n",
    "    losses = pretrain_gen(gen_pre_steps, gen_log_interval, pre_gen_path)\n",
    "    plt.plot(range(gen_log_interval, gen_pre_steps+1, gen_log_interval), losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Training the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_disc(steps, log_interval, save_path, profiling=True):\n",
    "    losses = []\n",
    "    disc_loss = 0.\n",
    "    if profiling:\n",
    "        start = time.perf_counter()\n",
    "    for i in range(steps):\n",
    "        real_imgs_batch = get_image_batch(real_gen)\n",
    "        disc_real_loss = disc.train_on_batch(real_imgs_batch, y_real)\n",
    "        \n",
    "        syn_imgs_batch = get_image_batch(syn_gen)\n",
    "        disc_refined_loss = disc.train_on_batch(syn_imgs_batch, y_refined)\n",
    "        \n",
    "        disc_loss += 0.5 * np.add(disc_real_loss, disc_refined_loss)\n",
    "\n",
    "        if (i+1) % log_interval == 0:\n",
    "            print('pre-training discriminator step {}/{}: loss = {:.5f}'.format(i+1, steps, disc_loss / log_interval))\n",
    "            losses.append(disc_loss / log_interval)\n",
    "            disc_loss = 0.\n",
    "\n",
    "    if profiling:\n",
    "        duration = time.perf_counter() - start\n",
    "        print('pre-training the discriminator model for {} steps lasted = {:.2f} minutes = {:.2f} hours'.format(steps, duration/60., duration/3600.))\n",
    "    \n",
    "    disc.save(save_path)\n",
    "    \n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and Dφ for 200 steps (one mini-batch for refined images, another for real)\n",
    "disc_pre_steps = 200\n",
    "disc_log_interval = 20\n",
    "\n",
    "pre_disc_path = os.path.join(cache_dir, 'disc_model_pre_trained_{}.h5'.format(disc_pre_steps))\n",
    "\n",
    "if os.path.isfile(pre_disc_path):\n",
    "    print('loading pretrained model weights')\n",
    "    disc.load_weights(pre_disc_path)\n",
    "else:\n",
    "    losses = pretrain_disc(disc_pre_steps, disc_log_interval, pre_disc_path)\n",
    "    plt.plot(range(disc_log_interval, disc_pre_steps+1, disc_log_interval), losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihb = ImageHistoryBuffer((0, img_height, img_width, channels), batch_size*100, batch_size)\n",
    "\n",
    "gan_loss = np.zeros(shape=len(combined_model.metrics_names))\n",
    "disc_loss_real = 0.\n",
    "disc_loss_refined = 0.\n",
    "disc_loss = 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_steps = 2000 # originally 10000\n",
    "k_d = 1 # number of discriminator updates per step\n",
    "k_g = 2 # number of generator updates per step\n",
    "log_interval = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# see Algorithm 1 in https://arxiv.org/pdf/1612.07828v1.pdf\n",
    "for i in range(nb_steps):    \n",
    "    # train the refiner\n",
    "    for _ in range(k_g * 2):\n",
    "        # sample a mini-batch of synthetic images\n",
    "        syn_img_batch = get_image_batch(syn_gen)\n",
    "        # update θ by taking an SGD step on mini-batch loss LR(θ)\n",
    "        loss = combined_model.train_on_batch(syn_img_batch, [syn_img_batch, y_real])\n",
    "        gan_loss = np.add(gan_loss, loss)\n",
    "    \n",
    "    for _ in range(k_d):\n",
    "        # sample a mini-batch of synthetic and real images\n",
    "        syn_img_batch = get_image_batch(syn_gen)\n",
    "        real_img_batch = get_image_batch(real_gen)\n",
    "        \n",
    "        # refine the synthetic images w/ the current refiner\n",
    "        refined_img_batch = refiner.predict_on_batch(syn_img_batch)\n",
    "        \n",
    "        # use a history of refined images\n",
    "        history_img_half_batch = ihb.get_from_image_history_buffer()\n",
    "        ihb.add_to_history_img_buffer(refined_img_batch)\n",
    "        \n",
    "        if len(history_img_half_batch):\n",
    "            refined_img_batch[:batch_size//2] = history_img_half_batch\n",
    "        \n",
    "        # update φ by taking an SGD step on mini-batch loss LD(φ)\n",
    "        real_loss = disc.train_on_batch(real_img_batch, y_real)\n",
    "        disc_loss_real += real_loss\n",
    "        ref_loss = disc.train_on_batch(refined_img_batch, y_refined)\n",
    "        disc_loss_refined += ref_loss\n",
    "        disc_loss += 0.5 * (real_loss + ref_loss)\n",
    "    \n",
    "    if (i+1) % log_interval == 0:\n",
    "        print('step: {}/{} | [D loss: (real) {:.5f} / (refined) {:.5f} / (combined) {:.5f}]'.format(i+1, \n",
    "                      nb_steps, disc_loss_real/log_interval, disc_loss_refined/log_interval,  disc_loss/log_interval))\n",
    "        \n",
    "        gan_loss = np.zeros(shape=len(combined_model.metrics_names))\n",
    "        disc_loss_real = 0.\n",
    "        disc_loss_refined = 0.\n",
    "        disc_loss = 0.\n",
    "    \n",
    "    if (i+1) % (log_interval*5) == 0:\n",
    "        figure_name = 'refined_image_batch_step_{}.png'.format(i)\n",
    "        print('Saving batch of refined images at adversarial step: {}.'.format(i))\n",
    "        \n",
    "        synthetic_image_batch = get_image_batch(syn_gen)[:plotted_imgs]\n",
    "        plot_batch(\n",
    "            np.concatenate((synthetic_image_batch, refiner.predict_on_batch(synthetic_image_batch))),\n",
    "            os.path.join(cache_dir, figure_name),\n",
    "            label_batch=['Synthetic'] * plotted_imgs + ['Refined'] * plotted_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refiner.save(os.path.join(cache_dir, 'refiner_model.h5'.format(disc_pre_steps)))\n",
    "disc.save(os.path.join(cache_dir, 'disc_model.h5'.format(disc_pre_steps)))\n",
    "combined_model.save(os.path.join(cache_dir, 'simgan_model.h5'.format(disc_pre_steps)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
